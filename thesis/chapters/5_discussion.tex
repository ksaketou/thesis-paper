\chapter{Discussion}

This section provides an overview of the mapping that took place on the main part of this review based on the criteria discussed in Chapter 3. We discuss trends noticed 
in each criterion regarding the usage of some techniques or any frequent patterns identified at the studied proposed approaches. This, finally, leads us to several conclusions 
about the current trends of NLP applications in the Software Testing field.\\

Starting from the Contribution Type characteristic, we notice a big tendency of the scientific community in developing frameworks and tools. This probably happens because 
these type of methods align with today's needs, since many times they combine complex functionality with applications to trending business scenarios. Frameworks and tools are 
widely used by corporations and smaller businesses in order to function fast and effectively. Consequently, the scientific community adapts to today's practices and aims at 
improving and facilitating the current practice by developing methods which easily adapt to the business world.\\

Our analysis, then, proceeded to the Software Testing Stage criterion with the Implementation stage being on top of the identified types. This stage is both a very important and 
also a very time consuming part of the Testing lifecycle, and sometimes it may act as a barrier in the current Agile Development methodology followed by many organizations. A very 
big number of the papers we studied in this review have created approaches to automate the test case creation process, with that requiring very little human effort to be completed. 
That way, test case development becomes almost fully automated and the duration of the testing process decreases significantly. This again proves that the academic research keeps 
up with current trending practices in order to contribute new and usefull knowledge.\\

As far as the Testing Type criterion is concerned, the vast majority of the approaches focuses on Automated Testing. As we have discussed in earlier sections of this review, the test automation 
field has been rapidly growing the last few years along with the overall tendency for automation existing in numerous parts of the corporate world and also everyday life. Taking into consideration 
the need for adaptation to new changes, the authors of many of the papers we refered here have brought automation processes one step closer to business practices. As we noticed, this is usually performed through 
the development of methods which automate tasks like test case creation and enhance different requirement analysis procedures.\\

Regarding the input type characteristic, we frequently encountered approaches that operate given documents containing natural language requirements and specifications about the tests to be developed. 
These documents act as a base for the whole testing process since they describe necessary prerequisites of the system under test. They also contain the expected functionality of the product based on which 
it is later going to be tested for. Consequently, regardless of the target of the proposed approach, requirement documents are an important source of information for software testing, which is sometimes 
difficult to make use of because of the fact that they contain natural language text that is not a very firendly data format for the computer to process. However, thanks to NLP, that kind of data types 
are being now more frequently and easily utilized.\\

Moving on to the output type, we find that test case code is one of the main data types generated by the proposed approaches. This finding aligns with the fact that many of the papers focus on the implementation 
stage, as we refered earlier. Thus, the test case generation process creates executable test code for the system under test.\\

The last criterion based on which we analyzed the papers is the NLP Techniques used in the approaches. We separated the NLP techniques in NLU and NLG methods and discussed them individually. What we eventually 
ended up on, is that the majority of the papers perform NLU tasks and use popular methods to achieve that. A widely and well-known technique used during Lexical Analysis is tagging and, more specifically, POS Tagging. 
POS Tagging identifies the part of speech to which the given words belong. However, apart from the classic use of POS Tagging, we identified several cases to which different customizations have been applied to the method. 
Those customizations are related to the choice of different tags than the classic parts of speech \cite{9240680}, whereas another paper uses BIO Tagging to further facilitate the process \cite{pedemonte2012towards}. 
Other authors even proceeded to create their own customized POS Tagger \cite{carvalho2014nat2testscr}.\\
Moreover, the use of NLP tools and libraries is also pretty often. Two distinct ones we noted are the Stanford CoreNLP library and the Python NLTK. Both of them are mainly used to support NLP parsing tasks, even though 
they provide a variety of functionalities. Word2Vec is another popular tool which turned out to be pretty popular among the papers reviewed. This tool facilitates the process of transforming the semantic representation of 
words into vectors, a task necessary in order to utilize word embeddings. To conclude, several statistical measures were also used by the authors with some of them being widely known in NLP community. The metrics applied 
in most of the papers are TF-IDF and cosine similarity. Both of them provide an indication of the semantic similarity between two elements using their vector representations.\\
Overall, we notice a tendency to continue using long-established popular NLP methods, and customizing them if necessary to achieve the requested goal. However, this doesn't mean that attempts to incorporate more unusual 
practices have not been made. LSTM RNNs and Relaxed Word-Mover's Distance are two examples of methods which we saw being used in a low frequency among the approaches. We believe, though, that the desired complexity 
of the technique and the quality of the result play an important role in the type of method which will be used during development. During this review, we discovered that it is not necessary to use complex methods in 
order to achieve substantial results and make a significant contribution to this knowledge area.
